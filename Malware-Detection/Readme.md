# Microsoft Malware Detection Case Study

## A Brief Introduction to the Microsoft Malware Detection Case Study

### 1. Business/Real-world Problem

#### 1.1 What is Malware?

The term malware is a contraction of malicious software. Put simply, malware is any piece of software that was written with the intent of doing harm to data, devices, or to people. [Source](https://www.avg.com/en/signal/what-is-malware)

#### 1.2 Problem Statement

In the past few years, the malware industry has grown very rapidly. Syndicates invest heavily in technologies to evade traditional protection, forcing anti-malware groups/communities to build more robust software to detect and terminate these attacks. The major part of protecting a computer system from a malware attack is to identify whether a given piece of file/software is malware.

#### 1.3 Dataset Overview

Microsoft has been very active in building anti-malware products over the years, running its anti-malware utilities over 150 million computers worldwide. This generates tens of millions of daily data points to be analyzed as potential malware. To be effective in analyzing and classifying such large amounts of data, we need to group them and identify their respective families. The dataset provided by Microsoft contains about 9 classes of malware. [Source](https://www.kaggle.com/c/malware-classification)

#### 1.4 Real-world/Business Objectives and Constraints

- Minimize multi-class error.
- Provide multi-class probability estimates.
- Malware detection should not take hours and block the user's computer. It should finish in a few seconds or a minute.

### 2. Data Overview

**Source**: [Kaggle Dataset](https://www.kaggle.com/c/malware-classification/data)

For every malware, there are two files:
- **.asm file**: [Read more](https://www.reviversoft.com/file-extensions/asm)
- **.bytes file**: The raw data contains the hexadecimal representation of the file's binary content, without the PE header.

The total training dataset consists of 200GB data, including 50GB of .bytes files and 150GB of .asm files:
- There are 10,868 .bytes files and 10,868 .asm files, totaling 21,736 files.
- There are 9 types of malware (9 classes) in the given data.

**Types of Malware:**
1. Ramnit
2. Lollipop
3. Kelihos_ver3
4. Vundo
5. Simda
6. Tracur
7. Kelihos_ver1
8. Obfuscator.ACY
9. Gatak

For each file, the raw data contains the hexadecimal representation of the file's binary content, without the PE header (to ensure sterility). You are also provided with a metadata manifest, which is a log containing various metadata information extracted from the binary, such as function calls, strings, etc. This was generated using the IDA disassembler tool. Your task is to develop the best mechanism for classifying files in the test set into their respective family affiliations.

### 3. High-Level Steps to Run the Case Study

1. Data overview
2. Mapping the real-world problem to an ML problem
3. Data Preprocessing and Exploratory Data Analysis (EDA)
4. Train, Test, and CV split
5. Modeling
6. Prediction

### 4. Major Challenges

1. **Disk Space**: This case study requires approximately 250 GB of free disk space.
2. **Time**: Approximately 48 hours to fetch features from .asm files (150 GB). Please use `data/asmoutputfile.csv` instead of processing all .asm files.
3. **Feature Engineering**: Image-based feature extraction from .asm files.

### 5. ML Models

#### 5.1 ML Models on .byte files unigram

1. Random Model 
2. K-Nearest Neighbour Classification 
3. Logistic Regression 
4. Random Forest Classifier
5. XgBoost Classification 
6. XgBoost Classification with best hyperparameters using RandomSearch 

#### 5.2 ML Models on .asm files unigram

1. K-Nearest Neighbour Classification 
2. Logistic Regression 
3. Random Forest Classifier
4. XgBoost Classification 
5. XgBoost Classification with best hyperparameters using RandomSearch 

#### 5.3 Select Best ML Models

1. Random Forest Classifier
2. XgBoost Classification 

#### 5.4 ML Models on .byte + .asm files unigrams

1. Random Forest Classifier
2. XgBoost Classification 
3. XgBoost Classification with best hyperparameters using RandomSearch

#### 5.5 ML Models on .byte files bigram

1. Random Forest Classifier
2. XgBoost Classification 
3. XgBoost Classification with best hyperparameters using RandomSearch

#### 5.6 ML Models on Image-Based Features Extraction from .asm files

1. Random Forest Classifier
2. XgBoost Classification 
3. XgBoost Classification with best hyperparameters using RandomSearch

#### 5.7 Feature Combinations with Best Models (Random Forest and XgBoost)

1. ASM image features + bytes unigram features
2. ASM unigram + ASM extracted image features
3. ASM unigram + ASM image features + ByteFile unigram

### 6. Result

The combination of ASM unigram + ASM image features + ByteFile unigram with XgBoost Classifier (best hyperparameters) achieved a log-loss < 0.01 (0.005282303659991528).

---
